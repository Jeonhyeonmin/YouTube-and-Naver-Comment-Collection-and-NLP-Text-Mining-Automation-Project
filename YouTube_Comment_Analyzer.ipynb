{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "from tkinter.filedialog import askdirectory\n",
    "import threading\n",
    "import os\n",
    "import pandas as pd\n",
    "import time, csv, pickle, warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from konlpy.tag import Hannanum\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.graph_objects as go\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "from gensim.models import LdaModel, Word2Vec\n",
    "from gensim import corpora\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeAnalyzerApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YouTube ëŒ“ê¸€ ë¶„ì„ê¸°\")\n",
    "        self.root.geometry(\"600x500\")\n",
    "        self.root.configure(bg=\"#f7f7f7\")\n",
    "\n",
    "        style = ttk.Style()\n",
    "        style.theme_use(\"clam\")\n",
    "\n",
    "        self.url_var = tk.StringVar()\n",
    "        self.path_var = tk.StringVar()\n",
    "\n",
    "        # --- UI êµ¬ì„± ---\n",
    "        ttk.Label(root, text=\"YouTube URL\", font=('Arial', 12)).pack(pady=10)\n",
    "        ttk.Entry(root, textvariable=self.url_var, width=60).pack()\n",
    "\n",
    "        ttk.Label(root, text=\"ì €ìž¥ ê²½ë¡œ ì„ íƒ\", font=('Arial', 12)).pack(pady=10)\n",
    "        frame = ttk.Frame(root)\n",
    "        frame.pack()\n",
    "        ttk.Entry(frame, textvariable=self.path_var, width=50).pack(side=tk.LEFT)\n",
    "        ttk.Button(frame, text=\"íƒìƒ‰\", command=self.browse).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        ttk.Button(root, text=\"ë¶„ì„ ì‹œìž‘\", command=self.run_analysis, width=20).pack(pady=20)\n",
    "\n",
    "        self.log = tk.Text(root, height=15, width=70)\n",
    "        self.log.pack(pady=10)\n",
    "        self.log.configure(state='disabled')\n",
    "\n",
    "    def browse(self):\n",
    "        path = askdirectory()\n",
    "        if path:\n",
    "            self.path_var.set(path)\n",
    "\n",
    "    def log_write(self, msg):\n",
    "        self.log.configure(state='normal')\n",
    "        self.log.insert(tk.END, f\"{msg}\\n\")\n",
    "        self.log.see(tk.END)\n",
    "        self.log.configure(state='disabled')\n",
    "        self.root.update()\n",
    "\n",
    "    def run_analysis(self):\n",
    "        threading.Thread(target=self.analyze).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze(self):\n",
    "        url = self.url_var.get()\n",
    "        save_path = self.path_var.get()\n",
    "        if not url or not save_path:\n",
    "            messagebox.showwarning(\"ìž…ë ¥ ì˜¤ë¥˜\", \"URLê³¼ ì €ìž¥ ê²½ë¡œë¥¼ ëª¨ë‘ ìž…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "\n",
    "        total_csv_path = os.path.join(save_path, \"total.csv\")\n",
    "        base_path = save_path + os.sep\n",
    "\n",
    "        try:\n",
    "            self.log_write(\"â–¶ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œìž‘...\")\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "                time.sleep(1.5)\n",
    "                new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.CSS_SELECTOR, \"#dismiss-button > a\").click()\n",
    "            except: pass\n",
    "\n",
    "            time.sleep(1.5)\n",
    "            buttons = driver.find_elements(By.CSS_SELECTOR, \"#more-replies > a\")\n",
    "            for button in buttons:\n",
    "                try:\n",
    "                    button.send_keys(Keys.ENTER)\n",
    "                    time.sleep(1)\n",
    "                    button.click()\n",
    "                except: continue\n",
    "\n",
    "            html_source = driver.page_source\n",
    "            soup = BeautifulSoup(html_source, 'html.parser')\n",
    "            comment_list = soup.select(\"ytd-comment-thread-renderer #content-text\")\n",
    "\n",
    "            comment_final = []\n",
    "            for comment in comment_list:\n",
    "                cleaned = comment.text.replace('\\n', '').replace('\\t', '').replace('\\r', '').strip()\n",
    "                comment_final.append(cleaned)\n",
    "\n",
    "            df = pd.DataFrame({\"Comment\": comment_final})\n",
    "            df.to_csv(total_csv_path, encoding=\"utf-8-sig\", index=False)\n",
    "            driver.quit()\n",
    "            self.log_write(\"âœ… ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "\n",
    "            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "            self.log_write(\"â–¶ ëª…ì‚¬ ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "            hannanum = Hannanum()\n",
    "            documents = [' '.join([w for w in hannanum.nouns(line) if len(w) >= 2]) for line in df[\"Comment\"].tolist()]\n",
    "            self.log_write(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "            # DTM/TTM ìƒì„±\n",
    "            vectorizer = CountVectorizer()\n",
    "            X = vectorizer.fit_transform(documents)\n",
    "            terms = vectorizer.get_feature_names_out()\n",
    "            ttm = pd.DataFrame(X.T.dot(X).toarray(), index=terms, columns=terms)\n",
    "            ttm.to_csv(base_path + 'ttm.csv', encoding='utf-8-sig')\n",
    "\n",
    "            # LDA ëª¨ë¸\n",
    "            self.log_write(\"â–¶ LDA ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "            dictionary = corpora.Dictionary([doc.split() for doc in documents])\n",
    "            corpus = [dictionary.doc2bow(doc.split()) for doc in documents]\n",
    "            lda_model = LdaModel(corpus, id2word=dictionary, num_topics=5, random_state=42)\n",
    "            with open(base_path + 'lda_model.pkl', 'wb') as f:\n",
    "                pickle.dump(lda_model, f)\n",
    "            lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "            pyLDAvis.save_html(lda_vis, base_path + 'LDAì‹œê°í™”.html')\n",
    "            self.log_write(\"âœ… LDA ì‹œê°í™” ì €ìž¥ ì™„ë£Œ\")\n",
    "\n",
    "            # Word2Vec\n",
    "            self.log_write(\"â–¶ Word2Vec í•™ìŠµ ì¤‘...\")\n",
    "            sentences = [doc.split() for doc in documents]\n",
    "            w2v_model = Word2Vec(sentences=sentences, vector_size=100, window=4, min_count=1, epochs=10, sg=1)\n",
    "            w2v_model.save(base_path + \"w2v.model\")\n",
    "\n",
    "            word_vectors = w2v_model.wv\n",
    "            vectors = word_vectors.vectors\n",
    "            words = word_vectors.index_to_key\n",
    "            with open(base_path + \"w2v_vectors.csv\", \"w\", encoding=\"utf-8-sig\", newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"word\"] + [f\"dim_{i}\" for i in range(vectors.shape[1])])\n",
    "                for word, vector in zip(words, vectors):\n",
    "                    writer.writerow([word] + list(vector))\n",
    "\n",
    "            pca = PCA(n_components=3)\n",
    "            reduced_vectors = pca.fit_transform(vectors)\n",
    "            kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "            labels = kmeans.fit_predict(vectors)\n",
    "\n",
    "            fig = go.Figure(data=[go.Scatter3d(\n",
    "                x=reduced_vectors[:, 0],\n",
    "                y=reduced_vectors[:, 1],\n",
    "                z=reduced_vectors[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(size=5, color=labels, colorscale='Viridis', opacity=0.8),\n",
    "                text=words,\n",
    "                hovertemplate='%{text}'\n",
    "            )])\n",
    "            fig.update_layout(scene=dict(xaxis_title='PCA1', yaxis_title='PCA2', zaxis_title='PCA3'))\n",
    "            fig.write_html(base_path + \"Word2vec3Dì‹œê°í™”.html\")\n",
    "            self.log_write(\"âœ… Word2Vec 3D ì‹œê°í™” ì™„ë£Œ\")\n",
    "\n",
    "            self.log_write(\"ðŸŽ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ì´ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            messagebox.showinfo(\"ì™„ë£Œ\", \"ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log_write(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "            messagebox.showerror(\"ì˜¤ë¥˜\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[0;32m      3\u001b[0m     app \u001b[38;5;241m=\u001b[39m YouTubeAnalyzerApp(root)\n\u001b[0;32m      4\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tk' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = YouTubeAnalyzerApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
